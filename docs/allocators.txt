The memory allocators in Merry are of two types: EndMeet allocator and Temporary allocator.

Temporary allocator is like the standard library provided allocator that provides memory for temporary things in the VM.
The memory allocated by this allocator is almost freed immediately. EndMeet allocator have what can be called pools: small and big pools.
The small pool is used when small amount of data is necessary whereas big pool is used when large amount of data is required.

Temporary allocator recycles the initial memory while EndMeet can and will keep requesting for new memory if the ones in its control are consumed.
EndMeet allocator is used by the VM's internal data structures for getting memory that is guranteed to be freed before the VM exits.

Both allocators are thread safe.

UPDATE:
These allocators are no more and we have only one allocator: Merry allocator. This allocator handles allocations in the same naive fashion as these old
allocators and only different in the sense that it is more well structured. This allocator has what we can call "Pools" of fixed size as well as misc sizes.
This allocator, upon initialization, gets more than 20KB of memory from the OS which it then divides into different "pages".
One page only fulfills the request of one size. For eg: pg_8 handles request for pointers. These specific sizes will be updated as the VM grows since this
allocator is specifically made for Merry so it makes sense that it is designed to handle the requests from the VM only.
The major issue with this allocator currently is, the allocator itself. It is slow, inefficient and leaves a lot memory footprint.
It doesn't handle memory properly, doesn't utilize memory properly, wastes a lot of bytes, asks for more memory than it utilizes.
But apart from these issues, the allocator doesn't handle requests for sizes that is larger than its page size. That is because it is not coded to handle that 
case. But it is for better. The only thing in the VM that would request more memory than the "page" size is the memory for memory page allocations.
But this will be handled by the memory itself.

Allocator is now a Legacy module. This module served its purpose as an allocator. The main motive for writing an allocator was to get rid of a problem that I faced while working on Aspire VM.
Aspire is another one of my VM that was discontinued because Malloc was not working as intended. The situation became so worse whilst trying to fix the error that it was irrepairable and thus discontinued.
For now malloc should work and provide memory for the VM without fail. If, in future, if the VM demands more than malloc can provide we can implement a way better allocator than the legacy one.
To be honest, the legacy allocator is the worst and yet the most memory efficient design I have made so far. Memory efficient in the sense that it breaks memory down to the needed size and limits fragmentation[mostly].
On the other hand, the size of metadata made it not "memory efficient". It was extremely slow, full of bugs, loopholes and bloat.